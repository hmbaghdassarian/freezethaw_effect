{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import packages\n",
      "load environmental variables\n"
     ]
    }
   ],
   "source": [
    "print('Import packages')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.special import binom\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#HERE\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import random\n",
    "\n",
    "from load_dotenv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, n_iter, alpha, lfc_min_thershold, base_mean_min_threshold, min_percentage, max_cutoff, normalization_type = 1000, 2, 0.1, 0.1, 0.1, 0.0, 0.2, 'RUV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('../data/rnaseq_pd.isaac.csv', index_col = 0)\n",
    "manifest = pd.read_excel('../data/manifest.xlsx', sheet_name = 2)\n",
    "\n",
    "\n",
    "polyA = d[(d['extraction'] == 'polyA') & (d['DX'] != 'Clontech-2') & (d['RINe'].notna()) & (d['DX'].notna())\n",
    "          & (d['final_freeze_thaw'].notna())]\n",
    "print(polyA.shape[0])\n",
    "polyA = [i.split('_')[0] for i in polyA.index]\n",
    "\n",
    "rD = d[(d['extraction'] == 'riboDep') & (d['DX'] != 'Clontech-2') & (d['DX'].notna())\n",
    "  & (d['RINe'].notna()) & (d['final_freeze_thaw'].notna())]\n",
    "print(rD.shape[0])\n",
    "rD = [i.split('_')[0] for i in rD.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(list1,list2):\n",
    "    num = len(set(list1).intersection(set(list2)))\n",
    "    denom = len(set(list1+list2))\n",
    "#     return num/denom\n",
    "    if denom != 0:\n",
    "        return num/denom\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 6357/12000 [00:00<00:00, 63566.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse subset labels\n",
      "Parse subset samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:00<00:00, 62992.12it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Parse subset labels')\n",
    "\n",
    "string_ = \"../data/iteration_labels.n.\"+ str(n) + '.n_iter.' + str(n_iter) + '.csv' \n",
    "  \n",
    "subset_labels = open(string_).read().splitlines()[1:]\n",
    "subset_labels = [i.split(',')[1] for i in subset_labels]\n",
    "subset_labels = [i[0:4] + i[i.index('_'):] for i in subset_labels]\n",
    "\n",
    "t = sorted(set(subset_labels))\n",
    "count = dict(zip(t,[1]*len(t)))\n",
    "\n",
    "for i in range(len(subset_labels)):\n",
    "    val = subset_labels[i]\n",
    "    subset_labels[i] = val + '_' + str(count[val])\n",
    "    count[val] += 1\n",
    "\n",
    "print('Parse subset samples')\n",
    "string_ = \"../data/iteration_samples.n.\"+ str(n) + '.n_iter.' + str(n_iter) + '.csv'\n",
    "\n",
    "subset_samples = open(string_).read().splitlines()[1:]\n",
    "subset_samples = [i.split('c(')[1][:-1].split(',') for i in subset_samples]\n",
    "\n",
    "i = subset_samples[0]\n",
    "for i in trange(len(subset_samples)):\n",
    "    list_ = subset_samples[i]\n",
    "    for j in range(len(list_)):\n",
    "        val = list_[j]\n",
    "        index = [k for k in range(len(val)) if val[k] == '\"']\n",
    "        list_[j] = val[index[0]+1:index[1]]\n",
    "    subset_samples[i] = list_\n",
    "subset_samples = [' '.join(i) for i in subset_samples]\n",
    "    \n",
    "if len(subset_samples) == len(subset_labels):\n",
    "    colLabel_to_subset = dict(zip(subset_labels,subset_samples))\n",
    "else:\n",
    "    raise ValueError('Samples or labels were parsed incorrectly')\n",
    "\n",
    "d___ = pd.DataFrame(data = {'colLabel': list(colLabel_to_subset.keys()), 'subset': list(colLabel_to_subset.values())})\n",
    "d___.to_csv('../data/colLabel_to_subset_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open and parse files\n"
     ]
    }
   ],
   "source": [
    "print('Open and parse files')\n",
    "# open and parse\n",
    "\n",
    "\n",
    "lfc_string = '../data/' + normalization_type + '.lfc.n.'+ str(n) + '.n_iter.' + str(n_iter) + '.csv'\n",
    "padj_string = '../data/' + normalization_type + '.padj.n.'+ str(n) + '.n_iter.' + str(n_iter) + '.csv'\n",
    "bm_string = '../data/' + normalization_type + '.base_mean.n.'+ str(n) + '.n_iter.' + str(n_iter) + '.csv'\n",
    "SE_string = \"../data/\" + normalization_type + '.' + \"lfc.SE.n.\" + str(n) + \".n_iter.\" + str(n_iter) + \".csv\"\n",
    "disp_string = \"../data/\" + normalization_type + '.' + \"lfc.dispersion.n.\" + str(n) + \".n_iter.\" + str(n_iter) + \".csv\"\n",
    "\n",
    "\n",
    "lfc_df = pd.read_csv(lfc_string, index_col = 0)\n",
    "padj_df = pd.read_csv(padj_string, index_col = 0)\n",
    "base_mean_df = pd.read_csv(bm_string, index_col = 0)\n",
    "lfc_SE_df = pd.read_csv(SE_string, index_col = 0)\n",
    "lfc_dispersion_df = pd.read_csv(disp_string, index_col = 0)\n",
    "\n",
    "\n",
    "lfc_df.columns, padj_df.columns, base_mean_df.columns = subset_labels, subset_labels,subset_labels\n",
    "lfc_SE_df.columns, lfc_dispersion_df.columns = subset_labels, subset_labels\n",
    "\n",
    "\n",
    "cols = lfc_df.columns.tolist()\n",
    "\n",
    "\n",
    "p = open(\"../data/actual_proportions.n.\"+ str(n) + '.n_iter.' + str(n_iter) + '.txt').read().splitlines()\n",
    "p = sorted(set([float(i) for i in p]))\n",
    "\n",
    "n_genes = lfc_df.shape[0]\n",
    "genes = lfc_df.index\n",
    "\n",
    "lfc_df.to_csv('../data/' + normalization_type + 'parsed_lfc_df_n' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "padj_df.to_csv('../data/' + normalization_type + 'parsed_padj_df_n' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "base_mean_df.to_csv('../data/' + normalization_type + 'parsed_base_mean_df_n' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "\n",
    "lfc_SE_df.to_csv('../data/' + normalization_type + 'parsed_lfc_SE_df_n' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "lfc_dispersion_df.to_csv('../data/' + normalization_type + 'parsed_lfc_dispersion_df_n' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some tests that things are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_p = [0.08, 0.13,0.17, 0.21,0.26,0.30,]\n",
    "ut_d = d___.copy()\n",
    "ut_d['Expected Length'] = ut_d['colLabel'].apply(lambda x: (ut_p.index(float(x.split('_')[0]))+2) * 2)\n",
    "ut_d['Actual Length'] = ut_d['subset'].apply(lambda x: len(x.split(' ')))\n",
    "if not ut_d['Actual Length'].equals(ut_d['Expected Length']):\n",
    "    raise ValueError('Incorrect parsing of subset labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate cutoff values and apprporiate gene lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Threshold genes')\n",
    "\n",
    "if (lfc_min_threshold == 0) or (base_mean_min_threshold == 0): \n",
    "    jaccard_genes = genes\n",
    "    concordance_genes = genes\n",
    "    correlation_genes = genes\n",
    "elif min_percentage == 0 or max_cutoff == 0:\n",
    "    \n",
    "    # filter by thresholds\n",
    "    median_df = pd.DataFrame(pd.np.empty((n_genes, 3)) * pd.np.nan) \n",
    "    median_df.columns = ['lfc', 'padj', 'base_mean']\n",
    "    median_df.index = genes\n",
    "    median_df['lfc'] = lfc_df.median(axis = 1).tolist()\n",
    "    median_df['padj'] = padj_df.median(axis = 1).tolist()\n",
    "    median_df['base_mean'] = base_mean_df.median(axis = 1).tolist()\n",
    "\n",
    "\n",
    "    min_cutoffs_lfc = median_df.quantile(lfc_min_threshold)\n",
    "    min_cutoffs_base_mean = median_df.quantile(base_mean_min_threshold)\n",
    "    concordance_genes = median_df[(median_df['base_mean']>min_cutoffs_base_mean['base_mean'])].index.tolist()\n",
    "    jaccard_genes = median_df[(median_df['lfc']> min_cutoffs_lfc['lfc']) & (median_df['base_mean']>min_cutoffs_base_mean['base_mean'])].index.tolist()\n",
    "    \n",
    "    correlation_genes = jaccard_genes\n",
    "else:\n",
    "    # filter by thresholds\n",
    "    median_df = pd.DataFrame(pd.np.empty((n_genes, 3)) * pd.np.nan) \n",
    "    median_df.columns = ['lfc', 'padj', 'base_mean']\n",
    "    median_df.index = genes\n",
    "    median_df['lfc'] = lfc_df.median(axis = 1).tolist()\n",
    "    median_df['padj'] = padj_df.median(axis = 1).tolist()\n",
    "    median_df['base_mean'] = base_mean_df.median(axis = 1).tolist()\n",
    "\n",
    "\n",
    "    min_cutoffs_lfc = median_df.quantile(lfc_min_threshold)\n",
    "    min_cutoffs_base_mean = median_df.quantile(base_mean_min_threshold)\n",
    "    concordance_genes = median_df[(median_df['base_mean']>min_cutoffs_base_mean['base_mean'])].index.tolist()\n",
    "    jaccard_genes = median_df[(median_df['lfc']> min_cutoffs_lfc['lfc']) & (median_df['base_mean']>min_cutoffs_base_mean['base_mean'])].index.tolist()\n",
    "\n",
    "    # if a gene has padj < max_cutoff for >= min_percentage*total_iterations, include it in the correlation analysis\n",
    "    significant_hits = padj_df[padj_df < max_cutoff].count(axis = 1)\n",
    "    correlation_genes = significant_hits[significant_hits > int(padj_df.shape[1]*min_percentage)].index.tolist()\n",
    "    correlation_genes = sorted(set(correlation_genes).intersection(jaccard_genes))\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "with open('../data/' + normalization_type + 'correlation_genes_n_' + str(n) + '_n_iter_' + str(n_iter) + '.txt','w') as f:\n",
    "    for i in correlation_genes:\n",
    "        f.write(i + '\\n')\n",
    "        \n",
    "with open('../data/' + normalization_type + 'concordance_genes_n_' + str(n) + '_n_iter_' + str(n_iter) + '.txt','w') as f:\n",
    "    for i in concordance_genes:\n",
    "        f.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dfs to store data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize dfs\n"
     ]
    }
   ],
   "source": [
    "print('Initialize dfs')\n",
    "# initialize dfs\n",
    "nrows = int(binom(n*n_iter,2))\n",
    "ncols = int(len(p))\n",
    "\n",
    "correlation_df = pd.DataFrame(pd.np.empty((nrows, ncols)) * pd.np.nan) \n",
    "correlation_df.columns = [str(i)[0:4] for i in p]\n",
    "correlation_sig_df, subsets_df = correlation_df.copy(), correlation_df.copy()\n",
    "\n",
    "concordance_df = pd.DataFrame(pd.np.empty((len(concordance_genes), 2*ncols)) * pd.np.nan)\n",
    "concordance_columns = []\n",
    "for col in correlation_df.columns:\n",
    "    concordance_columns.append(col + ' SD')\n",
    "    concordance_columns.append(col + ' mean abs(LFC)')\n",
    "concordance_df.columns = concordance_columns\n",
    "concordance_df.index = concordance_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concordance(p_, lfc_df = lfc_df, concordance_genes = concordance_genes):\n",
    "    '''Get gene-wise sd and mean(lfc) for a given proportion p_.'''\n",
    "    proportion_col = str(p_)[0:4]\n",
    "    p_cols = [i for i in cols if i[0:4] == proportion_col] \n",
    "    \n",
    "    # filter by thresholds\n",
    "    lfc_concordance = lfc_df.loc[concordance_genes,p_cols]\n",
    "    \n",
    "    ## CONCORDANCE\n",
    "    conc_sd = lfc_concordance.std(axis = 1).tolist()\n",
    "    conc_mean = lfc_concordance.abs().mean(axis = 1).tolist()\n",
    "    \n",
    "    return [conc_sd, conc_mean]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_sig(p_,lfc_df = lfc_df, alpha = alpha, correlation_genes = correlation_genes):\n",
    "    '''Get Spearman correlation with significance for a given proportion p_.'''\n",
    "\n",
    "    proportion_col = str(p_)[0:4]\n",
    "    p_cols = [i for i in cols if i[0:4] == proportion_col] \n",
    "\n",
    "    # generate subset df\n",
    "    lfc_corr = lfc_df.loc[correlation_genes,p_cols]\n",
    "\n",
    "    ## CORRELATION\n",
    "    lfc_corr = lfc_corr.fillna(0)\n",
    "\n",
    "    subset_labels = list(combinations(p_cols,2))\n",
    "    corr_vals = []\n",
    "    p_vals = []\n",
    "    # for sc in subset_labels:\n",
    "    for sc in subset_labels:\n",
    "        c = list(spearmanr(lfc_corr[sc[0]].values, lfc_corr[sc[1]].values))\n",
    "        corr_vals.append(c[0])\n",
    "        p_vals.append(c[1])\n",
    "\n",
    "    # Benjamini Hochberg correction\n",
    "    p_vals = list(multipletests(p_vals, alpha=alpha, method='fdr_bh', is_sorted=False, returnsorted=False)[0])\n",
    "\n",
    "    return list(zip(corr_vals, p_vals))\n",
    "    \n",
    "\n",
    "def get_subsets(p_):\n",
    "    \"\"\"Get actual subset combinations that data was generated on\"\"\"\n",
    "    \n",
    "    proportion_col = str(p_)[0:4]\n",
    "    p_cols = [i for i in cols if i[0:4] == proportion_col] \n",
    "    \n",
    "    subset_labels = list(combinations(p_cols,2))\n",
    "    S = [colLabel_to_subset[i[0]] + ' ; ' + colLabel_to_subset[i[1]] for i in subset_labels]\n",
    "    return S "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Get Correlation similarity with significance')\n",
    "pool = Pool(processes=cr) \n",
    "cor = pool.map(get_correlation_sig, p)\n",
    "pool.close()\n",
    "\n",
    "print('Get concordance')\n",
    "pool = Pool(processes=cr)\n",
    "con = pool.map(get_concordance, p)\n",
    "pool.close()\n",
    "\n",
    "print('Get subsets')\n",
    "pool = Pool(processes=cr)\n",
    "s = pool.map(get_subsets,p)\n",
    "pool.close()\n",
    "\n",
    "\n",
    "print('Write similarity metrics')\n",
    "for i in trange(len(p)):\n",
    "    correlation_df.iloc[:,i] = cor[i]\n",
    "    subsets_df.iloc[:,i] = s[i]\n",
    "    \n",
    "    index = i*2\n",
    "    concordance_df.iloc[:,index] = con[i][0]\n",
    "    concordance_df.iloc[:,index+1] = con[i][1]\n",
    "\n",
    "binarize_dict = {True: 1, False: 0}\n",
    "for i in trange(len(cor)):\n",
    "    corr_vals = [k[0] for k in cor[i]]\n",
    "    p_vals = [binarize_dict[k[1]] for k in cor[i]]\n",
    "    correlation_df.iloc[:,i] = corr_vals\n",
    "    correlation_sig_df.iloc[:,i] = p_vals\n",
    "    \n",
    "\n",
    "correlation_df.to_csv('../data/' + normalization_type + 'correlation_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "correlation_sig_df.to_csv('../data/' + normalization_type + 'correlation_sig_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "subsets_df.to_csv('../data/' + normalization_type + 'subsets_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "concordance_df.to_csv('../data/' + normalization_type + 'concordance_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get average metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get avg RIN and freeze thaw per subsets combination, serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get avg RIN and freeze thaw per subsets combination, parallel<--don't use, slower than serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load annot df\n",
      "Iterate through freeze thaw\n",
      "Put freeze thaw in df format\n",
      "Save freeze thaw csv\n",
      "Iterate through RIN\n",
      "Put RIN in df format\n",
      "Save RIN csv\n"
     ]
    }
   ],
   "source": [
    "def avg_val(annot, subsets_df, row, col):\n",
    "    \"\"\"Gets average RIN and freeze thaw for subset combination in subsets_df[row,col]\"\"\"\n",
    "    try:\n",
    "        comb = subsets_df.loc[row,col]\n",
    "        subset_1 = comb.split(';')[0].split(' ')[:-1]\n",
    "        subset_2 = comb.split(';')[1].split(' ')[1:]\n",
    "    except:\n",
    "        raise ValueError('Error from parsing, freeze thaw, row {}, col {}'.format(row,col)) \n",
    "#         return [float('nan'), float('nan')]\n",
    "    try:             \n",
    "        ft_1 = annot['final_freeze_thaw'][annot['Comment'].isin(subset_1)].sum()\n",
    "        ft_2 = annot['final_freeze_thaw'][annot['Comment'].isin(subset_2)].sum()\n",
    "        avg_ft = (ft_1 + ft_2)/(len(subset_1) + len(subset_2))\n",
    "        if len(subset_1) != len(subset_2):\n",
    "            raise ValueError('Subset parsing went wrong during avg ft and RIN calculation')\n",
    "    except:\n",
    "        raise ValueError('Error from freeze thaw calculation, row {}, col {}'.format(row,col))\n",
    "#         return [float('nan'), float('nan')]\n",
    "    \n",
    "    try:\n",
    "        RIN_1 = annot['RINe'][annot['Comment'].isin(subset_1)].sum()\n",
    "        RIN_2 = annot['RINe'][annot['Comment'].isin(subset_2)].sum()\n",
    "        avg_RIN = (RIN_1 + RIN_2)/(len(subset_1) + len(subset_2))\n",
    "    except:\n",
    "        raise ValueError('Error from RIN calculation, row {}, col {}'.format(row,col))\n",
    "#         return [float('nan'), float('nan')]       \n",
    "    return [avg_ft, avg_RIN]\n",
    "\n",
    "# print('Load subsets_df')\n",
    "# subsets_df = pd.read_csv('data/' + normalization_type + 'subsets_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv',index_col = 0)\n",
    "print('Load annot df')                \n",
    "annot = pd.read_excel('../data/manifest.xlsx',sheet_name = 5)\n",
    "\n",
    "def get_avg_FT(row, subsets_df = subsets_df, metric = 'Freeze Thaw', annot=annot):\n",
    "    \"\"\"Parallelize attaining average value metrics, iterates on rows of subsets_df\"\"\"\n",
    "    \n",
    "    if metric == 'Freeze Thaw':\n",
    "        index = 0\n",
    "    elif metric == 'RIN':\n",
    "        index = 1\n",
    "    \n",
    "    vals = [avg_val(annot,subsets_df,row,col)[index] for col in subsets_df.columns] \n",
    "    return vals\n",
    "\n",
    "def get_avg_RIN(row, subsets_df = subsets_df, metric = 'RIN', annot=annot):\n",
    "    \"\"\"Parallelize attaining average value metrics, iterates on rows of subsets_df\"\"\"\n",
    "    \n",
    "    if metric == 'Freeze Thaw':\n",
    "        index = 0\n",
    "    elif metric == 'RIN':\n",
    "        index = 1\n",
    "    \n",
    "    vals = [avg_val(annot,subsets_df,row,col)[index] for col in subsets_df.columns] \n",
    "    return vals\n",
    "\n",
    "print('Iterate through freeze thaw')\n",
    "pool = Pool(processes=cr) \n",
    "d_ft = pool.map(get_avg_FT, subsets_df.index)\n",
    "pool.close()\n",
    "print('Put freeze thaw in df format')\n",
    "freeze_thaw_df = pd.DataFrame(np.array(d_ft), columns = subsets_df.columns, index = subsets_df.index)\n",
    "print('Save freeze thaw csv')\n",
    "freeze_thaw_df.to_csv('../data/' + normalization_type + 'serial_average_freeze_thaw_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')\n",
    "\n",
    "\n",
    "print('Iterate through RIN')\n",
    "pool = Pool(processes=cr) \n",
    "d_RIN = pool.map(get_avg_RIN, subsets_df.index)\n",
    "pool.close()\n",
    "print('Put RIN in df format')\n",
    "RIN_df = pd.DataFrame(np.array(d_RIN), columns = subsets_df.columns, index = subsets_df.index)\n",
    "print('Save RIN csv')\n",
    "RIN_df.to_csv('../data/' + normalization_type + 'serial_average_RIN_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in colLabel_to_subset.items()}\n",
    "for i in range(10):\n",
    "    coord = (random.randint(0, subsets_df.shape[0]-1), random.randint(0, subsets_df.shape[1]-1))\n",
    "    test_sets = subsets_df.iloc[coord].split(' ; ')\n",
    "    set1, set2 = test_sets[0], test_sets[1]\n",
    "    actual_r = spearmanr(lfc_df.loc[correlation_genes, inv_map[set1]], lfc_df.loc[correlation_genes, inv_map[set2]])[0]\n",
    "    if correlation_df.iloc[coord] != actual_r:\n",
    "        raise ValueError('Problem with correlation df indexing')\n",
    "    jA = padj_df.loc[jaccard_genes, :][padj_df.loc[jaccard_genes, inv_map[set1]] < alpha].index.tolist()\n",
    "    jB = padj_df.loc[jaccard_genes, :][padj_df.loc[jaccard_genes, inv_map[set2]] < alpha].index.tolist()\n",
    "    if jaccard(jA,jB) != jaccard_df.iloc[coord]:\n",
    "        raise ValueError('Problem with jaccard df indexing')\n",
    "    \n",
    "    set1, set2 = set1.split(' '), set2.split(' ')\n",
    "    actual_ft = annot['final_freeze_thaw'][annot['Comment'].isin(set1)].sum() + annot['final_freeze_thaw'][annot['Comment'].isin(set2)].sum()\n",
    "    actual_ft = actual_ft/(len(set1) + len(set2))\n",
    "    if actual_ft != freeze_thaw_df.iloc[coord]:\n",
    "        raise ValueError('Freeze thaw parsing error')\n",
    "\n",
    "    actual_RIN = annot['RINe'][annot['Comment'].isin(set1)].sum() + annot['RINe'][annot['Comment'].isin(set2)].sum()\n",
    "    actual_RIN = actual_RIN/(len(set1) + len(set2))\n",
    "    if actual_RIN != RIN_df.iloc[coord]:\n",
    "        raise ValueError('RIN parsing error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate summary metrics\n"
     ]
    }
   ],
   "source": [
    "print('Generate summary metrics')\n",
    "# generate summary metrics \n",
    "n_combs = correlation_df.shape[0]\n",
    "proportion_col = [[p_]*n_combs for p_ in p]\n",
    "proportion_col = [item for sublist in proportion_col for item in sublist]\n",
    "\n",
    "subsets_col = [subsets_df[col].tolist() for col in subsets_df.columns]\n",
    "subsets_col = [item for sublist in subsets_col for item in sublist]\n",
    "\n",
    "correlation_col = [correlation_df[col].tolist() for col in correlation_df.columns]\n",
    "correlation_col = [item for sublist in correlation_col for item in sublist]\n",
    "\n",
    "correlation_sig_col = [correlation_sig_df[col].tolist() for col in correlation_sig_df.columns]\n",
    "correlation_sig_col = [item for sublist in correlation_sig_col for item in sublist]\n",
    "\n",
    "ft_col = [freeze_thaw_df[col].tolist() for col in freeze_thaw_df.columns]\n",
    "ft_col = [item for sublist in ft_col for item in sublist] \n",
    "\n",
    "RIN_col = [RIN_df[col].tolist() for col in RIN_df.columns]\n",
    "RIN_col = [item for sublist in RIN_col for item in sublist] \n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame(data = {'Subset Combination': subsets_col, 'Proportion': proportion_col, \n",
    "                                 'Correlation': correlation_col, 'Jaccard': jaccard_col, \n",
    "                                  'Avg Freeze Thaw': ft_col, 'Avg Rin': RIN_col, \n",
    "                                  'Correlation Significante': correlation_sig_col})\n",
    "summary_df.to_csv('../data/' + normalization_type + 'summary_df_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for glms\n",
    "sdf = summary_df.copy()\n",
    "sdf['Proportion'] = sdf['Proportion'].map(dict(zip(sorted(set(summary_df['Proportion'])), [4,6,8,10,12,14])))\n",
    "sdf.to_csv('../data/' + normalization_type + 'sdf_n_' + str(n) + '_n_iter_' + str(n_iter) + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
